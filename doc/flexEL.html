<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Shimeng Huang, Martin Lysy" />

<meta name="date" content="2022-03-10" />

<title>flexEL: A Fast and Flexible Framework for Empirical Likelihood Modeling</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore"><strong>flexEL</strong>: A Fast and Flexible Framework for Empirical Likelihood Modeling</h1>
<h4 class="author">Shimeng Huang, Martin Lysy</h4>
<h4 class="date">2022-03-10</h4>


<div id="TOC">
<ul>
<li><a href="#the-empirical-likelihood-framework">The Empirical Likelihood Framework</a><ul>
<li><a href="#basic-el-framework">Basic EL framework</a></li>
<li><a href="#usage-by-example">Usage by Example</a></li>
</ul></li>
<li><a href="#models-included-in-the-package">Models Included in the Package</a><ul>
<li><a href="#mean-and-quantile-regression-models">Mean and quantile regression models</a></li>
<li><a href="#location-scale-mean-and-quantile-regression-model">Location-Scale Mean and Quantile Regression Model</a></li>
</ul></li>
<li><a href="#el-for-right-censored-responses">EL for Right-censored Responses</a><ul>
<li><a href="#continuity-correction-of-el-under-right-censoring">Continuity-Correction of EL under right-censoring</a></li>
</ul></li>
<li><a href="#usage-in-c">Usage in C++</a></li>
<li><a href="#future-works">Future Works</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>


<div id="the-empirical-likelihood-framework" class="section level2">
<h2>The Empirical Likelihood Framework</h2>
<p>The Empirical Likelihood (EL) framework for regression is a semi-parametric model where inference about the regression parameters is conducted through maximizing the log EL function subject to specified moment conditions or estimating equations.</p>
<p>In the following two subsections, more details about the basic EL framework and a modified EL function when the responses are subject to right-censoring are provided.</p>
<div id="basic-el-framework" class="section level3">
<h3>Basic EL framework</h3>
<p>Suppose we have iid observations <span class="math inline">\(X_1, \ldots, X_n\)</span>, <span class="math inline">\(X_i \in \mathbb{R}^d\)</span>, such that <span class="math inline">\(E[g_k(X, {\boldsymbol{\theta}})] = 0\)</span> for <span class="math inline">\(k = 1,\ldots, m\)</span> where <span class="math inline">\(g_k\)</span>’s are real-valued functions and <span class="math inline">\({\boldsymbol{\theta}}\)</span> is the vector containing all regression parameters. These functions provide all information about the parameter <span class="math inline">\({\boldsymbol{\theta}}\)</span> of interest and are often called the estimating equations for <span class="math inline">\({\boldsymbol{\theta}}\)</span>.</p>
<p>The log empirical likelihood function (<strong>log EL</strong> function) is defined by
<span class="math display">\[
  \ell_{\textrm{EL}}({\boldsymbol{\theta}}) := \log\textrm{EL}({\boldsymbol{\theta}}) = \sum_{i=1}^n \log\hat{{\omega}}_i({\boldsymbol{\theta}}),
\]</span>
where for any given <span class="math inline">\({\boldsymbol{\theta}}\)</span>, the <span class="math inline">\(n\)</span>-dimensional probability weights vector <span class="math inline">\(\hat{{\omega}}({\boldsymbol{\theta}})\)</span> associated with the observations is the solution of the optimization problem
<span class="math display">\[
\begin{split}
  \max_{{\omega}}\quad &amp; \sum_{i=1}^n \log({\omega}_i) \\
  \text{s.t.}\quad &amp; \sum_{i=1}^n {\omega}_i\cdot g(X_i;{\boldsymbol{\theta}}) = 0 \\
  &amp; \sum_{i=1}^n {\omega}_i = 1 \\
  &amp; {\omega}_i \geq 0, \quad i=1,\cdots,n.
\end{split}
\]</span></p>
<p>The above inner optimization problem to find <span class="math inline">\(\hat{{\omega}}\)</span> given <span class="math inline">\({\boldsymbol{\theta}}\)</span> can be solved efficiently through solving the dual problem via a Newton-Raphoson algorithm which is provided in this package.</p>
<p>We also include the <strong>support adjustment</strong> introduced by <span class="citation">Chen, Variyath, and Abraham (2008)</span> in this package, which addresses the issue when the numerical problem (the above constrained optimization) has no solution.</p>
</div>
<div id="usage-by-example" class="section level3">
<h3>Usage by Example</h3>
<p>In order to perform inference using this package, two main steps are required from the user:</p>
<ol style="list-style-type: decimal">
<li>Design the estimating equations according to your model</li>
<li>Find estimates based on the log EL function</li>
</ol>
<p>In the first step, the key element required from the user is a function evaluating the <span class="math inline">\(G\)</span> matrix that was explained in the previous section.</p>
<p>In the second step, depending on your purpose and the property of the resulting log EL function, you may choose to use an optimization algorithm to find the maximum EL estimate, or to use a Markov Chain Monte Carlo sampler to obtain your estimate.</p>
<p>One thing to notice is that the log EL function may not be continuous and differentiable if the estimating equation is not so. In the quantile regression problem, for example, since the estimating equation for quantile is not continuous, a continuity correction is needed in order to directly optimize the log EL function. Alternatively, you may rely on global optimization algorithms such as simulated annealing, or Markov Chain Monte Carlo sampling to obtain a meaningful estimate.</p>
<p>Let’s use a simple two-parameter linear regression model as an example. Suppose we assume the following model
<span class="math display">\[
  y_i = \beta_0 + \beta_1x_i + {\epsilon}_i, \quad i=1,\cdots,n, 
\]</span>
where <span class="math inline">\(\epsilon_i \stackrel {\textrm{iid}}{\sim}\textrm{F}(\epsilon)\)</span> such that <span class="math inline">\(\textrm{E}(\epsilon_i) = 0\)</span> and <span class="math inline">\(\textrm{var}(\epsilon_i) = 1\)</span>. Notice that the distribution of <span class="math inline">\(\epsilon_i\)</span> is unkown, and no distribution assumption is made except for its mean and variance here.</p>
<p>As the first step, for any particular regression model, one should design an estimating function of the parameters, and implement a function (<code>evalG</code>) to calculate the corresponding <span class="math inline">\(G\)</span> matrix of dimension <span class="math inline">\(n\times m\)</span>, where <span class="math inline">\(n\)</span> is the number of observations, and <span class="math inline">\(m\)</span> is the dimension of the range of the estimating equation. This function can be directly implemented in R.</p>
<p>For example, for a linear regression model, the following estimating equation is used, which has a range of dimension <span class="math inline">\(m=p\)</span>, same as the dimension of the parameter vector <span class="math inline">\(\beta\)</span>:
<span class="math display">\[
  \textrm{E}[(y-x^T\beta)\cdot x] = 0,
\]</span>
which in its a sample form
<span class="math display">\[
  \sum_{i=1}^n (y_i-x_i^T\beta)\cdot x_i = 0.
\]</span>
In other words, the <span class="math inline">\(g\)</span> function is specified as
<span class="math display">\[
  g(x,y;\beta) = (y-x^T\beta)\cdot x.
\]</span></p>
<p>This can be implemented in R (<code>mr_evalG_R</code>) which returns the <span class="math inline">\(G\)</span> matrix:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>mr_evalG_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {</span>
<span id="cb1-2"><a href="#cb1-2"></a>  tX &lt;-<span class="st"> </span><span class="kw">t</span>(X)</span>
<span id="cb1-3"><a href="#cb1-3"></a>  yXb &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">c</span>(X <span class="op">%*%</span><span class="st"> </span>beta)</span>
<span id="cb1-4"><a href="#cb1-4"></a>  G &lt;-<span class="st"> </span><span class="kw">sweep</span>(tX, <span class="dt">MARGIN =</span> <span class="dv">2</span>, yXb, <span class="st">`</span><span class="dt">*</span><span class="st">`</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a>  <span class="kw">return</span>(<span class="kw">t</span>(G))</span>
<span id="cb1-6"><a href="#cb1-6"></a>}</span></code></pre></div>
<p>With <code>er_evalG_R</code> we can obtain a <span class="math inline">\(G\)</span> matrix for any given <span class="math inline">\(\beta\)</span>. This function can then be used to construct the log EL function, which is a function of the parameter <span class="math inline">\(\beta\)</span>.</p>
<p>To find the estimate of <span class="math inline">\(\beta\)</span>, we can use optimization algorithms in R such as <code>nlm</code> or <code>optim</code>. These functions require a starting value of the parameters to be optimized. In the above linear regression case, we can use <code>lm</code> in R, which assumes <span class="math inline">\(\epsilon_i\stackrel {\textrm{iid}}{\sim}\mathcal N(0,1)\)</span> but nonetheless should be able to provide a good starting point.</p>
<p>Here, for the convenience of using the minimization algorithm <code>nlm</code>, we implement the negative log EL:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>mr_neglogEL_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {</span>
<span id="cb2-2"><a href="#cb2-2"></a>  G &lt;-<span class="st"> </span><span class="kw">mr_evalG_R</span>(y, X, beta) <span class="co"># G matrix based on your regression problem</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  <span class="kw">return</span>(<span class="op">-</span>flexEL<span class="op">::</span><span class="kw">logEL</span>(<span class="dt">G =</span> G, <span class="dt">supp_adj =</span> <span class="ot">FALSE</span>)) <span class="co"># support correction not on</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>}</span></code></pre></div>
<p>Let’s simulate some data:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>gen_nct_eps &lt;-<span class="st"> </span><span class="cf">function</span>(n, df, ncp) {</span>
<span id="cb3-2"><a href="#cb3-2"></a>  m &lt;-<span class="st"> </span>ncp<span class="op">*</span><span class="kw">sqrt</span>(df<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">gamma</span>((df<span class="dv">-1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">gamma</span>(df<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>  v &lt;-<span class="st"> </span>df<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>ncp<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(df<span class="dv">-2</span>)<span class="op">-</span>ncp<span class="op">^</span><span class="dv">2</span><span class="op">*</span>df<span class="op">/</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">gamma</span>((df<span class="dv">-1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">gamma</span>(df<span class="op">/</span><span class="dv">2</span>))<span class="op">^</span><span class="dv">2</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>  eps &lt;-<span class="st"> </span>(<span class="kw">rt</span>(n, <span class="dt">df =</span> df, <span class="dt">ncp =</span> ncp)<span class="op">-</span>m)<span class="op">/</span><span class="kw">sqrt</span>(v)</span>
<span id="cb3-5"><a href="#cb3-5"></a>}</span>
<span id="cb3-6"><a href="#cb3-6"></a>n &lt;-<span class="st"> </span><span class="dv">500</span> <span class="co"># number of observations</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>b &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>) <span class="co"># beta_0 = 0.5, beta_1 = 1</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>eps &lt;-<span class="st"> </span><span class="kw">gen_nct_eps</span>(n, <span class="dt">df =</span> <span class="dv">20</span>, <span class="dt">ncp =</span> <span class="dv">1</span>) <span class="co"># a re-centered right-skewed non-central t distribution</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">rnorm</span>(n)) <span class="co"># n x 2 covariate matrix (intercept included)</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>y &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>b <span class="op">+</span><span class="st"> </span>eps <span class="co"># length n response vector</span></span></code></pre></div>
<p>With the <code>neglogEL</code> function, we can then obtain the estimate using <code>nlm</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>beta_init &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>X<span class="dv">-1</span>)) <span class="co"># obtain initial value</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>nlmout &lt;-<span class="st"> </span><span class="kw">nlm</span>(<span class="dt">f =</span> mr_neglogEL_R, <span class="dt">p =</span> beta_init, <span class="dt">y =</span> y, <span class="dt">X =</span> X)</span>
<span id="cb4-3"><a href="#cb4-3"></a>nlmout<span class="op">$</span>estimate</span></code></pre></div>
<pre><code>## [1] 0.5183124 1.0050678</code></pre>
<p>You may also provide the gradient of the estimating equations to the optimization algorithm, which can speed up the optimization.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>mr_dGdb_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {</span>
<span id="cb6-2"><a href="#cb6-2"></a>  lx &lt;-<span class="st"> </span><span class="kw">split</span>(X, <span class="kw">row</span>(X))</span>
<span id="cb6-3"><a href="#cb6-3"></a>  dg &lt;-<span class="st"> </span><span class="kw">lapply</span>(lx, <span class="cf">function</span>(x) <span class="kw">tcrossprod</span>(x,x))</span>
<span id="cb6-4"><a href="#cb6-4"></a>  <span class="kw">return</span>(dg)</span>
<span id="cb6-5"><a href="#cb6-5"></a>}</span>
<span id="cb6-6"><a href="#cb6-6"></a></span>
<span id="cb6-7"><a href="#cb6-7"></a>mr_neglogEL_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {</span>
<span id="cb6-8"><a href="#cb6-8"></a>  G &lt;-<span class="st"> </span><span class="kw">mr_evalG_R</span>(y, X, beta)</span>
<span id="cb6-9"><a href="#cb6-9"></a>  res_lst &lt;-<span class="st"> </span>flexEL<span class="op">::</span><span class="kw">logEL</span>(G, <span class="dt">supp_adj =</span> <span class="ot">FALSE</span>, <span class="dt">grad =</span> <span class="ot">TRUE</span>) </span>
<span id="cb6-10"><a href="#cb6-10"></a>  neglogel &lt;-<span class="st"> </span><span class="op">-</span>res_lst<span class="op">$</span>logel</span>
<span id="cb6-11"><a href="#cb6-11"></a>  dldG &lt;-<span class="st"> </span><span class="op">-</span>res_lst<span class="op">$</span>grad</span>
<span id="cb6-12"><a href="#cb6-12"></a>  dGdb &lt;-<span class="st"> </span><span class="kw">mr_dGdb_R</span>(y, X, beta)</span>
<span id="cb6-13"><a href="#cb6-13"></a>  grad_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> <span class="kw">nrow</span>(dldG), <span class="dt">ncol =</span> <span class="kw">ncol</span>(dldG))</span>
<span id="cb6-14"><a href="#cb6-14"></a>  <span class="cf">for</span> (ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(dldG)) {</span>
<span id="cb6-15"><a href="#cb6-15"></a>    grad_mat[,ii] &lt;-<span class="st"> </span>dGdb[[ii]] <span class="op">%*%</span><span class="st"> </span>dldG[ii,]</span>
<span id="cb6-16"><a href="#cb6-16"></a>  }</span>
<span id="cb6-17"><a href="#cb6-17"></a>  grad &lt;-<span class="st"> </span><span class="kw">colSums</span>(grad_mat)</span>
<span id="cb6-18"><a href="#cb6-18"></a>  <span class="kw">attr</span>(neglogel, <span class="st">&quot;gradient&quot;</span>) &lt;-<span class="st"> </span>grad</span>
<span id="cb6-19"><a href="#cb6-19"></a>  <span class="kw">return</span>(neglogel)</span>
<span id="cb6-20"><a href="#cb6-20"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>nlmout &lt;-<span class="st"> </span><span class="kw">nlm</span>(<span class="dt">f =</span> mr_neglogEL_R, <span class="dt">p =</span> beta_init, <span class="dt">y =</span> y, <span class="dt">X =</span> X)</span>
<span id="cb7-2"><a href="#cb7-2"></a>nlmout<span class="op">$</span>estimate</span></code></pre></div>
<pre><code>## [1] 0.5183124 1.0050678</code></pre>
</div>
</div>
<div id="models-included-in-the-package" class="section level2">
<h2>Models Included in the Package</h2>
<p>We include two types of regression models in this package: mean regression and quantile regression, and for each of them we provide a function to calculate the <code>G</code> matrix based on the estimating equation explained below.</p>
<div id="mean-and-quantile-regression-models" class="section level3">
<h3>Mean and quantile regression models</h3>
<p>The location models are the common linear regression models</p>
<p><span class="math display">\[
  y_i = {\boldsymbol{x}}_i&#39;{\boldsymbol{\beta}}+ {\epsilon}_i, \quad i=1,\cdots,n,
\]</span></p>
<p>where <span class="math inline">\({\epsilon}_i, i=1,\cdots,n\)</span> are iid with mean 0 and variance 1.</p>
<p>These two models are explained in the documentation of the functions <code>flexEL::mr_evalG</code> and <code>flexEL::qr_evalG</code> respectively, and are special cases of the location-scale models explained below where the scale function is fixed to be a constant <code>1</code>.</p>
</div>
<div id="location-scale-mean-and-quantile-regression-model" class="section level3">
<h3>Location-Scale Mean and Quantile Regression Model</h3>
<p>The location-scale models add a scale function as a multiplier of the error term, which helps in the case of heteroscedasticity</p>
<p><span class="math display">\[
  y_i = {\boldsymbol{x}}_i&#39;{\boldsymbol{\beta}}+ \sigma\cdot\exp({\boldsymbol{z}}_i&#39;{\boldsymbol{\gamma}})\cdot{\epsilon}_i, \quad i=1,\cdots,n,
\]</span></p>
<p>where <span class="math inline">\({\epsilon}_i, i=1,\cdots,n\)</span> are iid with mean 0 and variance 1.</p>
<p>The functions are provided in this package as <code>flexEL::mrls_evalG</code> and <code>flexEL::qrls_evalG</code>.</p>
<p>For mean regression, the estimating equation is constructed as the first derivative w.r.t <span class="math inline">\({\boldsymbol{\theta}}= ({\boldsymbol{\beta}}, {\boldsymbol{\gamma}}, \sigma^2)\)</span> of the quasi-likelihood function</p>
<p><span class="math display">\[
\begin{split}
  \textrm{E}\Bigl[\frac{y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}}}{\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}\cdot{\boldsymbol{x}}\Bigr] &amp;= 0 \\
  \textrm{E}\Bigl[(1-\frac{(y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}})^2}{\sigma^2\cdot\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})})\cdot{\boldsymbol{z}}\Bigr] &amp;= 0 \\
  \textrm{E}\Bigl[\frac{(y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}})^2}{\sigma^2\cdot\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}-1\Bigr] &amp;= 0.
\end{split}
\]</span></p>
<p>more details regarding the quasi-likelihood setup can be found in <span class="citation">Huang (2018)</span>.</p>
<p>For quantile regression, the <span class="math inline">\(\alpha\times 100\%\)</span> conditional quantile of <span class="math inline">\(y_i\)</span> is
<span class="math display">\[
  Q_{\alpha}(y_i|X_i) = X_i&#39;{\boldsymbol{\beta}}+ \sigma\cdot\exp(Z_i&#39;{\boldsymbol{\gamma}})\cdot\nu_{\alpha}.
\]</span>
so the vector of parameters is <span class="math inline">\({\boldsymbol{\theta}}= ({\boldsymbol{\beta}}, {\boldsymbol{\gamma}}, \sigma^2, \nu_{\alpha})\)</span>.</p>
<p>The estimating equations in this case include the above used for the mean regression but also one more targeting the quantile value, based on the “check function” introduced by <span class="citation">Koenker and Bassett Jr (1978)</span>.</p>
<p>If the <span class="math inline">\(\alpha\)</span>-th quantile value of <span class="math inline">\({\epsilon}_i\stackrel {\textrm{iid}}{\sim}(0,1)\)</span> is <span class="math inline">\(\nu_{\alpha}\)</span>, then <span class="math inline">\({\epsilon}_i-\nu_{\alpha}\)</span> has <span class="math inline">\(\alpha\)</span>-th quantile value <span class="math inline">\(0\)</span>. The estimator of <span class="math inline">\(\nu_{\alpha}\)</span> is then defined as
<span class="math display">\[
  \hat\nu_{\alpha} = \mathop{\mathrm{arg\,min}}_{\tilde\nu_{\alpha}} \textrm{E}\Biggl[\rho_{\alpha}\Bigl(\frac{y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}}}{\sigma\cdot\exp({\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}-\tilde\nu_{\alpha}\Bigr)\Biggr].
\]</span>
Therefore, the first derivative of this function is included in the set of estimating equations for location-scale quantile equations</p>
<p><span class="math display">\[
\begin{split}
  \textrm{E}\Bigl[\frac{y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}}}{\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}\cdot{\boldsymbol{x}}\Bigr] &amp;= 0 \\
  \textrm{E}\Bigl[\bigl(1-\frac{(y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}})^2}{\sigma^2\cdot\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}\bigr)\cdot{\boldsymbol{z}}\Bigr] &amp;= 0 \\
  \textrm{E}\Bigl[\frac{(y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}})^2}{\sigma^2\cdot\exp(2{\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}-1\Bigr] &amp;= 0 \\
  \textrm{E}\Bigl[\rho&#39;_{\alpha}\bigl(\frac{y-{\boldsymbol{x}}&#39;{\boldsymbol{\beta}}}{\sigma\cdot\exp({\boldsymbol{z}}&#39;{\boldsymbol{\gamma}})}-\nu_{\alpha}\bigr)\Bigr] &amp;= 0.
\end{split}
\]</span></p>
<p>In fact, <code>flexEL::qrls_evalG</code> can also calculate the <code>G</code> matrix for estimating parameters over multiple quantile levels at the same time, which is documented in its help page.</p>
<p>Moreover, as the check function used for the quantile regression estimation is not smooth, we also include a smoothed version of the check function in this package, which is controlled by the <code>sp</code> argument in <code>flexEL::qrls_evalG</code> function. Details of this setup can be found in <span class="citation">Huang (2018)</span>.</p>
</div>
</div>
<div id="el-for-right-censored-responses" class="section level2">
<h2>EL for Right-censored Responses</h2>
<p>When the response is time-to-event data such as survial time in many clinical studies, one situation that often occurs is right-censoring, one type of length-bias problem. Specifically, instead of observing the true survival time for each individual, what being observed is either the true survival time or the time this person dropped out of the study. That is, instead of observing <span class="math inline">\(y_i\)</span>, we observe <span class="math inline">\(u_i = \min(y_i,c_i)\)</span> and <span class="math inline">\(\delta_i=\mathfrak 1(y_i\leq c_i)\)</span>, where <span class="math inline">\(c_i\)</span> is a censoring variable that is assumed to be independent of <span class="math inline">\(y_i\)</span> given covariate <span class="math inline">\(x_i\)</span>.</p>
<p>The log EL function under right-censoring (<strong>log CEL</strong>) is defined as
<span class="math display">\[
  \ell_{\textrm{CEL}} := \log\textrm{CEL}({\boldsymbol{\theta}}) = \sum_{i=1}^n \delta_i\cdot\log\hat{w_i}({\boldsymbol{\theta}}) + (1-\delta_i)\cdot\log(\sum_{j: e_j \geq e_i}\hat{w_i}({\boldsymbol{\theta}}))
\]</span></p>
<p>Given a specific <span class="math inline">\({\boldsymbol{\theta}}\)</span>, let <span class="math inline">\(e_i\)</span> be the residual of the <span class="math inline">\(i\)</span>-th observation for <span class="math inline">\(i=1,\cdots,n\)</span>. Similar as before, <span class="math inline">\(\hat{\omega}({\boldsymbol{\theta}})\)</span> is the solution of
<span class="math display">\[
\begin{split}
  \max_{{\omega}}\quad &amp; \sum_{i=1}^n \delta_i\cdot\log({\omega}_i) + (1-\delta_i)\cdot\log(\sum_{j: e_j\geq e_i}{\omega}_i) \\
  \text{s.t.}\quad &amp; \sum_{i=1}^n {\omega}_i\cdot g(x_i,y_i;{\boldsymbol{\theta}}) = 0 \\
  &amp; \sum_{i=1}^n {\omega}_i = 1 \\
  &amp; {\omega}_i \geq 0, \quad i=1\cdots,n.
\end{split}
\]</span></p>
<p>Notice that the same <span class="math inline">\(G\)</span> matrix as in the fully-observed data case is supplied to this optimization.</p>
<p>Due to right-censoring, this inner optimization problem turns out to be difficult to solve directly as in the previous case. Instead, the solution can be obtained through an EM algorithm.</p>
<p>Notice that the EL function in this case is not continous with respect to <span class="math inline">\({\boldsymbol{\theta}}\)</span>, which brings more difficulties to obtain an optimal solution. To deal with this problem, we introduce a continuity-correction method in the following subsection.</p>
<div id="continuity-correction-of-el-under-right-censoring" class="section level3">
<h3>Continuity-Correction of EL under right-censoring</h3>
<p>Let <span class="math inline">\(S\)</span> be a transformed sigmoid function, i.e.,
<span class="math display">\[
S_{ij}({\boldsymbol{\theta}};s) := S(e_i({\boldsymbol{\theta}})-e_j({\boldsymbol{\theta}});s)
  = \frac{1}{1+\exp(s\cdot(e_i({\boldsymbol{\theta}})-e_j({\boldsymbol{\theta}})))}.
\]</span>
where <span class="math inline">\(s &gt; 0\)</span> is a smoothing parameter and <span class="math inline">\(e_i({\boldsymbol{\theta}})\)</span> is residual <span class="math inline">\(i\)</span> given <span class="math inline">\({\boldsymbol{\theta}}\)</span>.</p>
<p>The log smoothed censored EL <strong>(log SCEL)</strong> is then defined as
<span class="math display">\[
  \ell_{\textrm{SCEL}}({\boldsymbol{\theta}}) = \sum_{i=1}^n \Bigl[\delta_i\log(w_i({\boldsymbol{\theta}})) +
    (1-\delta_i)\log(\sum_{j=1}^n S_{ij}({\boldsymbol{\theta}};s)\cdot w_j({\boldsymbol{\theta}}))\Bigr].
\]</span></p>
<p>This log SCEL function is then continuous in <span class="math inline">\({\boldsymbol{\theta}}\)</span> given <span class="math inline">\(w({\boldsymbol{\theta}})\)</span> is continous in <span class="math inline">\({\boldsymbol{\theta}}\)</span> and <span class="math inline">\(e({\boldsymbol{\theta}})\)</span> is continuous in <span class="math inline">\({\boldsymbol{\theta}}\)</span>. The continuity of these two depend on the construction of the regression model.</p>
<p>In <code>flexEL::logEL</code>, the argument <code>sp</code> corresponds to this smoothing parameter.</p>
</div>
</div>
<div id="usage-in-c" class="section level2">
<h2>Usage in C++</h2>
<p>One can also implement a regression model in C++ following the header file <code>mean_reg_model.h</code>. The key element of this is once again the <code>EvalG</code> method which defines the regression model. Then one can export this method as in <code>mean_reg_model_exports.cpp</code>.</p>
<p>Or, if one wish to use the C++ api directly, the steps are as below:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">/// </span><span class="an">@file</span><span class="co"> </span><span class="cv">example.cpp</span></span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="co">// [[Rcpp::depends(&quot;flexEL&quot;)]]</span></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="co">// [[Rcpp::depends(&quot;RcppEigen&quot;)]]</span></span>
<span id="cb9-5"><a href="#cb9-5"></a></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="pp">#include </span><span class="im">&lt;RcppEigen.h&gt;</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="pp">#include </span><span class="im">&lt;flexEL/gen_el.h&gt;</span></span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="pp">#include </span><span class="im">&lt;flexEL/mean_reg_model.h&gt;</span></span>
<span id="cb9-10"><a href="#cb9-10"></a></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="co">/// Empirical likelihood function for the mean regression model.</span></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="co">///</span></span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="co">/// </span><span class="an">@param[in]</span><span class="co"> </span><span class="cv">beta</span><span class="co"> Vector of `n_cov` regression coefficients.</span></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="co">/// </span><span class="an">@param[in]</span><span class="co"> </span><span class="cv">X</span><span class="co"> Covariate matrix of size `n_obs x n_cov`.</span></span>
<span id="cb9-15"><a href="#cb9-15"></a><span class="co">/// </span><span class="an">@param[in]</span><span class="co"> </span><span class="cv">y</span><span class="co"> Response vector of length `n_obs`.</span></span>
<span id="cb9-16"><a href="#cb9-16"></a><span class="co">///</span></span>
<span id="cb9-17"><a href="#cb9-17"></a><span class="co">/// </span><span class="an">@return</span><span class="co"> Scalar value of the log empirical likelihood function.</span></span>
<span id="cb9-18"><a href="#cb9-18"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb9-19"><a href="#cb9-19"></a><span class="dt">double</span> example_logel(Eigen::VectorXd beta,</span>
<span id="cb9-20"><a href="#cb9-20"></a>                     Eigen::MatrixXd X,</span>
<span id="cb9-21"><a href="#cb9-21"></a>                     Eigen::VectorXd y) {</span>
<span id="cb9-22"><a href="#cb9-22"></a>  flexEL::MeanRegModel MR(y, X.transpose());</span>
<span id="cb9-23"><a href="#cb9-23"></a>  <span class="dt">int</span> n_obs = MR.get_n_obs();</span>
<span id="cb9-24"><a href="#cb9-24"></a>  <span class="dt">int</span> n_eqs = MR.get_n_eqs();</span>
<span id="cb9-25"><a href="#cb9-25"></a>  MatrixXd G = MatrixXd::Zero(MR.get_n_eqs(), MR.get_n_obs());</span>
<span id="cb9-26"><a href="#cb9-26"></a>  MR.eval_G(G, beta);</span>
<span id="cb9-27"><a href="#cb9-27"></a>  flexEL::GenEL GEL(n_obs, n_eqs);</span>
<span id="cb9-28"><a href="#cb9-28"></a>  GEL.set_supp_adj(true); <span class="co">// turn on support correction</span></span>
<span id="cb9-29"><a href="#cb9-29"></a>  <span class="dt">double</span> logel = GEL.logel(G);</span>
<span id="cb9-30"><a href="#cb9-30"></a>  <span class="cf">if</span>(!GEL.has_converged_nr()) {</span>
<span id="cb9-31"><a href="#cb9-31"></a>    <span class="co">// convergence check</span></span>
<span id="cb9-32"><a href="#cb9-32"></a>    logel = -std::numeric_limits&lt;<span class="dt">double</span>&gt;::infinity();</span>
<span id="cb9-33"><a href="#cb9-33"></a>  }</span>
<span id="cb9-34"><a href="#cb9-34"></a>  <span class="cf">return</span>(logel);</span>
<span id="cb9-35"><a href="#cb9-35"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>Rcpp<span class="op">::</span><span class="kw">sourceCpp</span>(<span class="st">&quot;example.cpp&quot;</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a>bb &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a>n_obs &lt;-<span class="st"> </span><span class="dv">200</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>n_eqs &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">rnorm</span>(n_obs))</span>
<span id="cb10-6"><a href="#cb10-6"></a>eps &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n_obs)</span>
<span id="cb10-7"><a href="#cb10-7"></a>y &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>bb <span class="op">+</span><span class="st"> </span>eps</span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="kw">example_logel</span>(<span class="kw">c</span>(<span class="fl">0.75</span>, <span class="fl">1.25</span>), X, y)</span></code></pre></div>
<pre><code>## [1] -1107.018</code></pre>
<p>There are more options that you can set for the InnerEL object via <code>set_opts</code> which you can look up in the doxygen documentation in the <code>src/html</code> folder.</p>
</div>
<div id="future-works" class="section level2">
<h2>Future Works</h2>
<ol style="list-style-type: decimal">
<li>The gradient approach has not been integrated in the C++ code</li>
<li>Confidence intervals evaluation has not been included in the package</li>
</ol>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-chen-et-al08">
<p>Chen, Jiahua, Asokan Mulayath Variyath, and Bovas Abraham. 2008. “Adjusted Empirical Likelihood and Its Properties.” <em>Journal of Computational and Graphical Statistics</em> 17 (2): 426–43.</p>
</div>
<div id="ref-huang18">
<p>Huang, Shimeng. 2018. “Empirical Likelihood Quantile Regression for Right-Censored Data.” Master’s thesis, University of Waterloo.</p>
</div>
<div id="ref-koenker-bassett78">
<p>Koenker, Roger, and Gilbert Bassett Jr. 1978. “Regression Quantiles.” <em>Econometrica: Journal of the Econometric Society</em>, 33–50.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
