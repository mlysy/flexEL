---
title:
  formatted: "\\pkg{flexEL}: A Fast and Flexible Framework for Empirical Likelihood Modeling"
  plain: "flexEL: A Fast and Flexible Framework for Empirical Likelihood Modeling"
author: 
  - name: Shimeng Huang
    affiliation: University of Waterloo
  - name: Martin Lysy
    affiliation: University of Waterloo
    address:
      - 200 University Avenue West
      - Ontario, Canada
    email: \email{mlysy@uwaterloo.ca}
abstract: >
  Here is the abstract.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
date: "`r Sys.Date()`"
documentclass: jss
classoption: article
header-includes:
  - \usepackage{caption}
  - \captionsetup[table]{skip=.1em}
  - \usepackage{bm}
  - \usepackage{amsmath}
  - \newcommand{\yy}{\bm y}
  - \newcommand{\tth}{\bm \theta}
  - \newcommand{\lla}{\bm \lambda}
  - \newcommand{\R}{\mathbb R}
  - \renewcommand{\gg}{\bm g}
  - \newcommand{\w}{\omega}
  - \renewcommand{\l}{\lambda}
  - \renewcommand{\L}{\mathcal{L}}
  - \newcommand{\EL}{\textrm{EL}}
  - \newcommand{\str}[1]{{#1}^{\star}}
  - \DeclareMathOperator*{\argmax}{arg\,max}
output: 
  bookdown::pdf_book:
    toc: false
    template: jss-template.tex
    # keep_tex: true
    # keep_md: true
    highlight: tango
    # highlight_bw: false
    # md_extensions: +tex_math_dollars
    # latex_engine: xelatex
  html_document:
    keep_md: true
bibliography: references.bib  
---

```{r setup, include = FALSE}
library(knitr)
## knitr::knit_hooks$set(
##   prompt = function(before, options, envir) {
##     eng <- options$engine
##     if(eng %in% c("sh", "bash")) {
##       pr <- "$ "
##     } else if(eng == "R") {
##       pr <- "R> "
##     } else {
##       pr <- "> "
##     }
##     options(prompt = pr)
## })
## options(prompt = "R> ",
##         continue = "+  ",
##         width = 70,
##         useFancyQuotes = FALSE)
knitr::opts_chunk$set(comment="",
                      prompt = TRUE,
                      R.options = list(prompt = "R> ",
                                       continue = "+  ",
                                       width = 70,
                                       useFancyQuotes = FALSE))
embed_file <- function(file, lang) {
  cat(paste0("```", lang), readLines(file), "```", sep = "\n")
}
```

# Introduction

Empirical likelhood (EL) method allows statisticians to construct partially specified models via moment conditions. Although an EL model does not assume any parametric familiy of the data, the estimator is in some sense as efficient as a fully parametric model [@qin-lawless1994].

The EL approach can be traced back to @thomas-grunkemeier1975. Its current framework was mainly developed by @owen1988, @owen1990, and @owen1991. Over the years, many researchers have extended or generalized the method, but there has not been a flexible and efficient software available to the public. The existing softwares are either written in a high-level programming language for which inner optimization is not efficient, or are designed for specific regression problems (e.g. \pkg{emplik}, \pkg{gelS4}). There is also no software that provides EL method for right-censored data.

This paper describes a framework we designed for EL researchers to develop fast and efficient implementations of their own EL models and related methods. We provide a computationally efficient R package called \pkg{flexEL} which is flexible enough for users to solve any type of regression problems with minimum programming effort. The computational efficiency is achieved by a C++ implementation of the inner optimization algorithm. Other than the main functionality of reglular EL estimation, the package also provides support correction, continuity correction under right-censoring, gradient calculation, as well as various mean and quantile regression models for which the details will be described in the later sections.

- Motivation: What is EL?  

	- Partially specified model via moment conditions (estimand).  
	- An estimator that's "in some sense" as efficient as full parametric likelihood (refs).

- Gap: Much theory, but relatively little software (should list the ones we know of).  

	- Bulk of computations done via a convex optimization problem dual to eq (??) (describe here or relegate to methods section).  
	- Existing libraries are either written in a high-level programming language for which inner optimization is not efficient, or provide efficient implementation but for e.g., pecific regression problems (like \pkg{emplik} in \proglang{R}).
	
- Contribution: A framework for EL researchers to develop fast/efficient implementations of their own EL models and related methods.

	- This is achieved with a low-level C++ implementation of the NR method using Eigen for linear algebra.
	
	- Other EL techniques provided include: support correction, censoring, gradients.  (is this too technical for intro?)
	
- How to address theory/existing literature?

	- Should definitely cite as much existing literature as possible, theoretical or otherwise.
	
	- As for explanations, I think in many cases just the "equation" is good enough (for example, for support correction can just show how to add the observation, and explain that this is known to make NR have a unique solution for every `\bm{\theta}`.
	
# Methodology

## Basics

Let $\yy_1,\cdots,\yy_n$ where $\yy_i\in\R^{d+1}$ be iid observations from an unknown distribution $F_0(\yy)$, about which a parameter of interest $\tth$ is defined as satisfying an $m$-dimensional moment condition:
\begin{equation} \label{eq:momcond}
  \E\bigl[\gg(\yy;\tth)\bigr] = 0,
\end{equation}
where $\gg(\yy, \tth) = \bigl( g_1(\yy, \tth), \ldots, g_m(\yy, \tth) \bigr)$.

The empirical likelihood $\EL(\tth)$ is defined as the profile likelihood over the distribution function of $\yy$:
\begin{equation} \label{eq:elF}
  \EL(\tth) = \max_{F \in \mathcal F(\tth)} \prod_{i=1}^n \mathrm{d} F(\yy_i),
\end{equation}
where for any given $\tth$, $\mathcal F(\tth)$ is the set of (valid) distribution functions satisfying \eqref{eq:momcond}.

It was shown @owen1988 that for any $\tth$, the maximum of \eqref{eq:elF} must be achieved by a PMF putting all mass on the support of the observed data $\yy_1, \cdots, \yy_n$, such that the infinite-dimensional profile likelihood \eqref{eq:elF} reduces to a finite-dimensional one:
\begin{equation}
  \EL(\tth) = \prod_{i=1}^n \hat{\w_i}(\tth),
\end{equation}
where the $n$-dimensional vector of probability weights $\hat{\w}(\tth)$ associated with the observations is the solution of an inner optimization problem which will be referred to as \textbf{EL inner optimization}
\begin{equation} \label{eq:noncensopt}
\begin{split}
  \max_{\w}\quad & \sum_{i=1}^n \log(\w_i) \\
  \text{s.t.}\quad & \sum_{i=1}^n \w_i\cdot \gg(\yy_i;\tth) = 0 \\
  & \sum_{i=1}^n \w_i = 1 \\
  & \w_i \geq 0, \quad i=1,\cdots,n,
\end{split}
\end{equation}

The problem in (\ref{eq:noncensopt}) is a constrained convex optimization problem, and its optimal solution can be found via Lagrangian function, similar to the steps in @owen1990. Specifically, the Lagrangian funciton can be set up as 
\begin{equation} \label{eq:lagrange}
  \L = \sum_{i=1}^n \log(\w_i) + n\l^T(\sum_{i=1}^n \w_i \cdot g(\yy_i;\tth)) - \mu(\sum_{i=1}^n \w_i -1)
\end{equation}

Provided that $\bm 0$ is in the convex full of the points $\gg(\yy_1;\tth),\cdots,\gg(\yy_n;\tth)$, a unique optimal weight vector exist and can be shown to be
\begin{equation}
  \hat{\w_i}(\tth) = \frac{1}{n\cdot[1 - \hat \lla'(\tth) \gg(\yy_i;\tth)]},
\end{equation}
where the vector $\hat{\lla}(\tth)$ solves the unconstrained optimization problem
\begin{equation}
\hat{\l}(\tth) = \argmax_{\lla} \sum_{i=1}^n \str\log\Big(1 - \lla' \gg(\yy_i;\tth)\Big),
\end{equation}
and where
\begin{equation}
\str\log(x) = \begin{cases} \log(x) & x \ge \tfrac 1 n \\ -\tfrac 1 2 n^2 x^2 + 2 n x - \tfrac 3 2 - \log(n) & x < \tfrac 1 n \end{cases}.
\end{equation}

@qin-lawless1994 has shown that $\lla(\tth)$ is a continuous differentiable function of $\tth$ provided that convex hull condition is satisfied with $\tth$ and $\sum_{i=1}^n \gg(\yy_i;\tth)g'(\yy_i;\tth)$ is positive definite. However, the support of $\tth$ is not necessarily a convex set, as demonstrated by @chaudhuri-et-al2017.

In the case that we are only interested in one parameter $\theta$ of an unknown distribution $F$, @owen1990 has shown that the limiting distribution of the EL ratio statistic is chi-square. For a vector of parameters, @qin-lawless1994 shows that the EL ratio statistic is asymptotic normal. This means that we can derive confidence intervals of the paramters accordingly.

With the Lagrangian function in (\ref{eq:lagrange}) , we can also derive the gradient of $\L$ with respect to the matrix $G = [\gg(\yy_1;\tth), \cdots, \gg(\yy_n;\tth)]$, such that given the gradient of $G$ with respect to the paramters of interest $\tth$, we can obtain the gradient of L with respect to $\tth$, and with which we can employ a gradient based optimization algorithm to find the optimal solution of the estimator.

- Dual problem.

- Uncertainty.  Either chi-square inversion for single parameters, or turns out that mode-quadrature (like MLE) also gives asymptotic normality, cf Qin-Lawless94.

- Might wish to provide gradient here, for optimization over theta.

## Support Correction

## Censoring

- What this is and how we estimate it with \pkg{flexEL} (EM algorithm, give the steps).

# Illustrations

## Mean Regression

- Show users how to create their own `Gfun` and use this from \proglang{R}.  

- Can include gradient-based optimization here as well.  I suggest to use `optim(method = "BFGS")` for optimization, not `nlm()` (it's just more complicated/annoying).  I would say use `nlminb()` which is way faster than `optim()`, but for some reason R Core suggests to use the other optimizers instead...

## Quantile Regression

- What it is, smoothness correction, present built-in function for this.

## Built-in Models

- We have a bunch of these: quantile vs mean regression, and location vs location-scale.

- Censoring as well.

- Should we put all this in the Methods section?  Have separate illustrations for some or all?

## Bayesian EL

- Good to illustrate with \proglang{Stan} NUTS algorithm, because we've implemented it already and \proglang{Stan} is a really good autodiff engine + best NUTS implementation.

- Can illustrate with the example from the JRSSB EL-HMC paper.

# Conclusion

- Everything below here are just tests for using JSS Markdown.

# Numbering

## Equations

Here's a reference to equation \@ref(eq:xyz).
\begin{equation}
x + y = z.
(\#eq:xyz)
\end{equation}
Here's an unnumbered equation:
\[
a/b = c.
\]
Here's some inline math: $y = \exp(x^2 - 1)$.

## Figures

Reference to Figure \@ref(fig:plot).  Also an example of embedding \proglang{R} code.
```{r plot, fig.cap = "A simple plot."}
x <- {function(y) {
  y + 1:10
}}(3)
x
plot(x, pch = x, col = x)
```

## Tables

Reference to Table \@ref(tab:mtcars).
```{r mtcars, echo = FALSE}
knitr::kable(head(mtcars[, 1:8], 5), booktabs = TRUE,
             caption = "A table of the first 5 rows of the mtcars data.")
```

# Embedded Files

<!-- ## C++ File -->

\subsection[C++ File alpha + beta]{C++ File $\alpha + \beta$}

- LaTeX in heading doesn't seem to work.  [Here's](https://github.com/jgm/pandoc/issues/3555) how far I got with this.
- In fact, seems to be a pure LaTeX problem, in that `latexmk` compile of tex output takes several tries to get it right.
- Working solution: Use `\subsection[plaintext]{latex}` instead of Markdown section.
- New problem: `\tightlist` not defined...

```{r, echo = FALSE, results = "asis"}
embed_file("foo.h", "cpp")
```

## R Markdown File

```{r, echo = FALSE, results = "asis"}
embed_file("foo.Rmd", "bash")
```
