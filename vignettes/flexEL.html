<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Shimeng Huang, Martin Lysy" />

<meta name="date" content="2020-07-18" />

<title>flexEL: A Fast and Flexible Framework for Empirical Likelihood Modeling</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore"><code>flexEL</code>: A Fast and Flexible Framework for Empirical Likelihood Modeling</h1>
<h4 class="author"><em>Shimeng Huang, Martin Lysy</em></h4>
<h4 class="date"><em>2020-07-18</em></h4>


<div id="TOC">
<ul>
<li><a href="#the-empirical-likelihood-framework">The Empirical Likelihood Framework</a><ul>
<li><a href="#basic-el-framework">Basic EL framework</a></li>
<li><a href="#el-for-right-censored-responses">EL for Right-censored Responses</a></li>
<li><a href="#continuity-correction-of-el-under-right-censoring">Continuity-Correction of EL under right-censoring</a></li>
</ul></li>
<li><a href="#usage-of-flexel-explained-by-examples">Usage of <code>flexEL</code> Explained by Examples</a><ul>
<li><a href="#usage-in-r">Usage in R</a></li>
<li><a href="#usage-in-c">Usage in C++</a></li>
</ul></li>
<li><a href="#models-included-in-the-package">Models Included in the Package</a></li>
<li><a href="#future-works">Future Works</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="the-empirical-likelihood-framework" class="section level2">
<h2>The Empirical Likelihood Framework</h2>
<p>The Empirical Likelhood (EL) framework for regression is a semi-parametric model where inference about the regression parameters is conducted through maximizing the log EL function subject to specified moment conditions or estimating equations.</p>
<p>In the following two subsections, more details about the basic EL framwork and a modified EL function when the responses are under right-censoring are provided.</p>
<div id="basic-el-framework" class="section level3">
<h3>Basic EL framework</h3>
<p>Suppose we observe covariates <span class="math inline">\(x_i\in{\mathbb R}^d\)</span> and responses <span class="math inline">\(y_i\in{\mathbb R}\)</span> for <span class="math inline">\(i=1,\cdots,n\)</span>. Let’s denote the vector containing all regression parameters by <span class="math inline">\({{{\boldsymbol{\theta}}}}\in{\mathbb R}^p\)</span>.</p>
<p>The log empirical likelihood function (<strong>log EL</strong> function) is defined by <span class="math display">\[
  \ell_{{\textrm{EL}}}({{{\boldsymbol{\theta}}}}) := \log{\textrm{EL}}({{{\boldsymbol{\theta}}}}) = \sum_{i=1}^n \log\hat{{{\omega}}_i}({{{\boldsymbol{\theta}}}}),
\]</span> where for any given <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>, the <span class="math inline">\(n\)</span>-dimensional probability weights vector <span class="math inline">\(\hat{{{\omega}}}({{{\boldsymbol{\theta}}}})\)</span> associated with the observations is the solution of the optimization problem <span class="math display">\[
\begin{split}
  \max_{{{\omega}}}\quad &amp; \sum_{i=1}^n \log({{\omega}}_i) \\
  \text{s.t.}\quad &amp; \sum_{i=1}^n {{\omega}}_i\cdot g(x_i,y_i;{{{\boldsymbol{\theta}}}}) = 0 \\
  &amp; \sum_{i=1}^n {{\omega}}_i = 1 \\
  &amp; {{\omega}}_i \geq 0, \quad i=1,\cdots,n.
\end{split}
\]</span> In the above, <span class="math inline">\(g\)</span> is a real-valued function whose range is in <span class="math inline">\({\mathbb R}^m\)</span> that satisfies <span class="math display">\[
  {\textrm{E}}[g(x,y;{{{\boldsymbol{\theta}}}})] = 0.
\]</span> This function provides all information about the parameter <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span> of interest and is often called the estimating equation for <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>.</p>
<p>The above inner optimization problem to find <span class="math inline">\(\hat{{{\omega}}}\)</span> given <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span> can be solved efficiently through solving the dual problem via a Newton-Raphoson algorithm.</p>
<p>An important element for EL inference is the matrix constructed by the values of this function evaluated at each of the observed values for a given <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>. Let’s denote this matrix of dimension <span class="math inline">\(n\times m\)</span> by <span class="math inline">\(G\)</span>, whose rows correspoind to the observations: <span class="math display">\[
  G := [g(x_1,y_1;{{{\boldsymbol{\theta}}}})^T,\cdots,g(x_n,y_n;{{{\boldsymbol{\theta}}}})^T]
\]</span></p>
<p>To use this package, specifying the <span class="math inline">\(G\)</span> matrix according to your regression model is the only requirement.</p>
<p>We also include the <strong>support adjustment</strong> introduced by <span class="citation">Chen, Variyath, and Abraham (2008)</span> in this package, which addresses the issue when the numerical problem (the above constrained optimization) has no solution.</p>
</div>
<div id="el-for-right-censored-responses" class="section level3">
<h3>EL for Right-censored Responses</h3>
<p>When the response is time-to-event data such as survial time in many clinical studies, one situation that often occurs is right-censoring, one type of length-bias problem. Specifically, instead of observing the true survival time for each individual, what being observed is either the true survival time or the time this person dropped out of the study. That is, instead of observing <span class="math inline">\(y_i\)</span>, we observe <span class="math inline">\(u_i = \min(y_i,c_i)\)</span> and <span class="math inline">\(\delta_i=\mathfrak 1(y_i\leq c_i)\)</span>, where <span class="math inline">\(c_i\)</span> is a censoring variable that is assumed to be independent of <span class="math inline">\(y_i\)</span> given covariate <span class="math inline">\(x_i\)</span>.</p>
<p>The log EL function under right-censoring (<strong>log CEL</strong>) is defined as <span class="math display">\[
  \ell_{{\textrm{CEL}}} := \log{\textrm{CEL}}({{{\boldsymbol{\theta}}}}) = \sum_{i=1}^n \delta_i\cdot\log\hat{w_i}({{{\boldsymbol{\theta}}}}) + (1-\delta_i)\cdot\log(\sum_{j: e_j \geq e_i}\hat{w_i}({{{\boldsymbol{\theta}}}}))
\]</span></p>
<p>Given a specific <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>, let <span class="math inline">\(e_i\)</span> be the residual of the <span class="math inline">\(i\)</span>-th observation for <span class="math inline">\(i=1,\cdots,n\)</span>. Similar as before, <span class="math inline">\(\hat{{\omega}}({{{\boldsymbol{\theta}}}})\)</span> is the solution of <span class="math display">\[
\begin{split}
  \max_{{{\omega}}}\quad &amp; \sum_{i=1}^n \delta_i\cdot\log({{\omega}}_i) + (1-\delta_i)\cdot\log(\sum_{j: e_j\geq e_i}{{\omega}}_i) \\
  \text{s.t.}\quad &amp; \sum_{i=1}^n {{\omega}}_i\cdot g(x_i,y_i;{{{\boldsymbol{\theta}}}}) = 0 \\
  &amp; \sum_{i=1}^n {{\omega}}_i = 1 \\
  &amp; {{\omega}}_i \geq 0, \quad i=1\cdots,n.
\end{split}
\]</span></p>
<p>Notice that the same <span class="math inline">\(G\)</span> matrix as in the fully-observed data case is supplied to this optimization.</p>
<p>Due to right-censoring, this inner optimization problem turns out to be difficult to solve directly as in the previous case. Instead, the solution can be obtained through an EM algorithm.</p>
<p>Notice that the EL function in this case is not continous with respect to <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>, which brings more difficulties to obtain an optimal solution. To deal with this problem, we introduce a continuity-correction method in the following subsection.</p>
</div>
<div id="continuity-correction-of-el-under-right-censoring" class="section level3">
<h3>Continuity-Correction of EL under right-censoring</h3>
<p>Let <span class="math inline">\(S\)</span> be a transformed sigmoid function, i.e., <span class="math display">\[
S_{ij}({{{\boldsymbol{\theta}}}};s) := S(e_i({{{\boldsymbol{\theta}}}})-e_j({{{\boldsymbol{\theta}}}});s)
  = \frac{1}{1+\exp(s\cdot(e_i({{{\boldsymbol{\theta}}}})-e_j({{{\boldsymbol{\theta}}}})))}.
\]</span> where <span class="math inline">\(s &gt; 0\)</span> is a smoothing parameter and <span class="math inline">\(e_i({{{\boldsymbol{\theta}}}})\)</span> is residual <span class="math inline">\(i\)</span> given <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>.</p>
<p>The log smoothed censored EL <strong>(log SCEL)</strong> is then defined as <span class="math display">\[
  \ell_{{\textrm{SCEL}}}({{{\boldsymbol{\theta}}}}) = \sum_{i=1}^n \Bigl[\delta_i\log(w_i({{{\boldsymbol{\theta}}}})) +
    (1-\delta_i)\log(\sum_{j=1}^n S_{ij}({{{\boldsymbol{\theta}}}};s)\cdot w_j({{{\boldsymbol{\theta}}}}))\Bigr].
\]</span></p>
<p>This log SCEL function is then continuous in <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span> given <span class="math inline">\(w({{{\boldsymbol{\theta}}}})\)</span> is continous in <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span> and <span class="math inline">\(e({{{\boldsymbol{\theta}}}})\)</span> is continuous in <span class="math inline">\({{{\boldsymbol{\theta}}}}\)</span>. The continuity of these two depend on the construction of the regression model.</p>
</div>
</div>
<div id="usage-of-flexel-explained-by-examples" class="section level2">
<h2>Usage of <code>flexEL</code> Explained by Examples</h2>
<p>Upon observing data, the purpose is to find the estimates of the parameters of your semi-parametric regression model. To achieve this, two steps are required:</p>
<ol style="list-style-type: decimal">
<li>Construct the log EL function according to your model</li>
<li>Obtain an estimate based on the log EL function</li>
</ol>
<p>In the first step, the only key element required from the user is a function evaluating the <span class="math inline">\(G\)</span> matrix that was explained in the previous section.</p>
<p>In the second step, depending on your purpose and the property of the resulting log EL function, you may choose to use an optimization algorithm to find the maximum EL estimate, or to use a Markov Chain Monte Carlo sampler to obtain your estimate.</p>
<p>One thing to notice is that the log EL function may not be continuous and differentiable if the estimating equation is not so. In the quantile regression problem, for example, since the estimating equation for quantile is not continuous, a continuity correction is needed in order to directly optimize the log EL function. Alternatively, you may rely on global optimization algorithms such as simulated annealing, or Markov Chain Monte Carlo sampling to obtain a meaningful estimate.</p>
<p>Let’s use a simple two-parameter linear regression model as an example. Suppose we assume the following model <span class="math display">\[
  y_i = \beta_0 + \beta_1x_i + {{\epsilon}}_i, \quad i=1,\cdots,n, 
\]</span> where <span class="math inline">\(\epsilon_i {\stackrel {\textrm{iid}}{\sim}}{\textrm{F}}(\epsilon)\)</span> such that <span class="math inline">\({\textrm{E}}(\epsilon_i) = 0\)</span> and <span class="math inline">\({\textrm{var}}(\epsilon_i) = 1\)</span>. Notice that the distribution of <span class="math inline">\(\epsilon_i\)</span> is unkown, and no distribution assumption is made except for its mean and variance here.</p>
<p>Let’s start by simulating some data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gen_nct_eps &lt;-<span class="st"> </span><span class="cf">function</span>(n, df, ncp) {
  m &lt;-<span class="st"> </span>ncp<span class="op">*</span><span class="kw">sqrt</span>(df<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="kw">gamma</span>((df<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">gamma</span>(df<span class="op">/</span><span class="dv">2</span>)
  v &lt;-<span class="st"> </span>df<span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>ncp<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(df<span class="op">-</span><span class="dv">2</span>)<span class="op">-</span>ncp<span class="op">^</span><span class="dv">2</span><span class="op">*</span>df<span class="op">/</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">gamma</span>((df<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">gamma</span>(df<span class="op">/</span><span class="dv">2</span>))<span class="op">^</span><span class="dv">2</span>
  eps &lt;-<span class="st"> </span>(<span class="kw">rt</span>(n, <span class="dt">df =</span> df, <span class="dt">ncp =</span> ncp)<span class="op">-</span>m)<span class="op">/</span><span class="kw">sqrt</span>(v)
}
n &lt;-<span class="st"> </span><span class="dv">500</span> <span class="co"># number of observations</span>
b &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>) <span class="co"># beta_0 = 0.5, beta_1 = 1</span>
eps &lt;-<span class="st"> </span><span class="kw">gen_nct_eps</span>(n, <span class="dt">df =</span> <span class="dv">20</span>, <span class="dt">ncp =</span> <span class="dv">1</span>) <span class="co"># a re-centered right-skewed non-central t distribution</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">rnorm</span>(n)) <span class="co"># n x 2 covariate matrix (intercept included)</span>
y &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>b <span class="op">+</span><span class="st"> </span>eps <span class="co"># length n response vector</span></code></pre></div>
<p>We explain how to use this package to conduct inference for your regression model either in R or in C++ in the following two sections.</p>
<div id="usage-in-r" class="section level3">
<h3>Usage in R</h3>
<p>As the first step, for any particular regression model, one should design an estimating function of the parameters, and implement a function (<code>evalG</code>) to calculate the corresponding <span class="math inline">\(G\)</span> matrix of dimension <span class="math inline">\(n\times m\)</span>, where <span class="math inline">\(n\)</span> is the number of observations, and <span class="math inline">\(m\)</span> is the dimension of the range of the estimating equation. This function can be directly implemented in R.</p>
<p>For example, for a linear regression model, the following estimating equation is used, which has a range of dimension <span class="math inline">\(m=p\)</span>, same as the dimension of the parameter vector <span class="math inline">\(\beta\)</span>: <span class="math display">\[
  {\textrm{E}}[(y-x^T\beta)\cdot x] = 0,
\]</span> which in its a sample form <span class="math display">\[
  \sum_{i=1}^n (y_i-x_i^T\beta)\cdot x_i = 0.
\]</span> In other words, the <span class="math inline">\(g\)</span> function is specified as <span class="math display">\[
  g(x,y;\beta) = (y-x^T\beta)\cdot x.
\]</span></p>
<p>This can be implemented in R (<code>mr_evalG_R</code>) which returns the <span class="math inline">\(G\)</span> matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mr_evalG_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {
  tX &lt;-<span class="st"> </span><span class="kw">t</span>(X)
  yXb &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">c</span>(X <span class="op">%*%</span><span class="st"> </span>beta)
  G &lt;-<span class="st"> </span><span class="kw">sweep</span>(tX, <span class="dt">MARGIN =</span> <span class="dv">2</span>, yXb, <span class="st">`</span><span class="dt">*</span><span class="st">`</span>)
  <span class="kw">return</span>(<span class="kw">t</span>(G))
}</code></pre></div>
<p>With <code>evalG</code> we can obtain a <span class="math inline">\(G\)</span> matrix for any given <span class="math inline">\(\beta\)</span>. This function can then be used to construct the log EL function, which is a function of the parameter <span class="math inline">\(\beta\)</span>.</p>
<p>To find the estimate, we can use optimization algorithms in R such as <code>nlm</code> or <code>optim</code>. These functions require a starting value of the parameters to be optimized. In the above linear regression case, we can use <code>lm</code> in R to obtain it, which assumes <span class="math inline">\(\epsilon_i{\stackrel {\textrm{iid}}{\sim}}{\mathcal N}(0,1)\)</span> but nonetheless should be able to provide a good starting point.</p>
<p>Here, for the convience of using the minimization algorithm <code>nlm</code>, let’s implement the negative log EL:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mr_neglogEL_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {
  G &lt;-<span class="st"> </span><span class="kw">mr_evalG_R</span>(y, X, beta) <span class="co"># G matrix based on your regression problem</span>
  <span class="kw">return</span>(<span class="op">-</span>flexEL<span class="op">::</span><span class="kw">logEL</span>(<span class="dt">G =</span> G))
}</code></pre></div>
<p>With the <code>neglogEL</code> function, we can then obtain the estimate using <code>nlm</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta_init &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>X<span class="op">-</span><span class="dv">1</span>)) <span class="co"># obtain initial value</span>
nlmout &lt;-<span class="st"> </span><span class="kw">nlm</span>(<span class="dt">f =</span> mr_neglogEL_R, <span class="dt">p =</span> beta_init, <span class="dt">y =</span> y, <span class="dt">X =</span> X)
nlmout<span class="op">$</span>estimate</code></pre></div>
<pre><code>## [1] 0.5613544 0.9567111</code></pre>
<p>You may also provide the gradient of the estimating equations to the optimization algorithm, which can speed up the optimization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mr_deltaG_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {
  lx &lt;-<span class="st"> </span><span class="kw">split</span>(X, <span class="kw">row</span>(X))
  dg &lt;-<span class="st"> </span><span class="kw">lapply</span>(lx, <span class="cf">function</span>(x) <span class="kw">tcrossprod</span>(x,x))
  <span class="kw">return</span>(dg)
}

mr_neglogEL_R &lt;-<span class="st"> </span><span class="cf">function</span>(y, X, beta) {
  G &lt;-<span class="st"> </span><span class="kw">mr_evalG_R</span>(y, X, beta)
  res_lst &lt;-<span class="st"> </span>flexEL<span class="op">::</span><span class="kw">logEL</span>(G, <span class="dt">return_dldG =</span> <span class="ot">TRUE</span>)
  neglogel &lt;-<span class="st"> </span><span class="op">-</span>res_lst<span class="op">$</span>logel
  dldG &lt;-<span class="st"> </span>res_lst<span class="op">$</span>dldG
  dGdb &lt;-<span class="st"> </span><span class="kw">mr_deltaG_R</span>(y, X, beta)
  grad_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> <span class="kw">nrow</span>(dldG), <span class="dt">ncol =</span> <span class="kw">ncol</span>(dldG))
  <span class="cf">for</span> (ii <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(dldG)) {
    grad_mat[,ii] &lt;-<span class="st"> </span>dGdb[[ii]] <span class="op">%*%</span><span class="st"> </span>dldG[,ii]
  }
  grad &lt;-<span class="st"> </span><span class="kw">rowSums</span>(grad_mat)
  <span class="kw">attr</span>(neglogel, <span class="st">&quot;gradient&quot;</span>) &lt;-<span class="st"> </span>grad
  <span class="kw">return</span>(neglogel)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlmout &lt;-<span class="st"> </span><span class="kw">nlm</span>(<span class="dt">f =</span> mr_neglogEL_R, <span class="dt">p =</span> beta_init, <span class="dt">y =</span> y, <span class="dt">X =</span> X)
nlmout<span class="op">$</span>estimate</code></pre></div>
<pre><code>## [1] 0.5613544 0.9567111</code></pre>
</div>
<div id="usage-in-c" class="section level3">
<h3>Usage in C++</h3>
<p>One can also implement a regression model in C++ following the header file <code>mean_reg_model.h</code>. The key element of this is once again the <code>EvalG</code> method which defines the regression model. Then one can export this method as in <code>mean_reg_model_exports.cpp</code>.</p>
<p>Or, if one wish to use the C++ api directly, the steps are as below:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;RcppEigen.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;random&gt;</span><span class="pp"> </span><span class="co">// for simulating some data here</span>
<span class="pp">#include </span><span class="im">&quot;inner_el.h&quot;</span>
<span class="pp">#include </span><span class="im">&quot;mean_reg_model.h&quot;</span><span class="pp"> </span><span class="co">// using mean regression as an example, this could be your model C++ header file</span>

<span class="co">// simulate some data</span>
Eigen::VectorXd X = Eigen::VectorXd::Random(<span class="dv">2</span>,<span class="dv">20</span>);
Eigen::VectorXd beta(<span class="dv">2</span>);
beta &lt;&lt; <span class="dv">1</span>, <span class="dv">2</span>;
<span class="dt">static</span> default_random_engine e(time(<span class="dv">0</span>));
<span class="dt">static</span> normal_distribution&lt;<span class="dt">double</span>&gt; n(<span class="dv">0</span>,<span class="dv">1</span>);
Eigen::VectorXd eps(<span class="dv">20</span>);
<span class="cf">for</span> (<span class="dt">int</span> ii=<span class="dv">0</span>; i&lt;<span class="dv">20</span>; i++) {
  eps &lt;&lt; n(e);
}
Eigen::VectorXd y = beta.transpose() * X + eps;

<span class="co">// instantiate the model and EL objects</span>
flexEL::MeanRegModel MR(y, X); <span class="co">// instantiate a mean regression object</span>
flexEL::InnerEL EL(MR.get_n_obs(), MR.get_n_eqs()); <span class="co">// instantiate an EL object with dimention of G matrix</span>
EL.set_opts(support = true); <span class="co">// set support correction</span>

<span class="co">// evaluate EL for a particular beta</span>
Eigen::VectorXd beta = Eigen::VectorXd::Random(<span class="dv">2</span>);
MR.EvalG(EL.get_ref_G(), beta);
<span class="dt">int</span> n_iter;
<span class="dt">double</span> max_err;
EL.LambdaNR(n_iter, max_err);
EL.EvalOmegas();
EL.LogEL();</code></pre></div>
<p>There are more options that you can set for the InnerEL object via <code>set_opts</code> which you can look up in the doxygen documentation in the <code>src/html</code> folder.</p>
</div>
</div>
<div id="models-included-in-the-package" class="section level2">
<h2>Models Included in the Package</h2>
<ol style="list-style-type: decimal">
<li>Mean and quantile regression models</li>
</ol>
<p><span class="math display">\[
  y_i = {{{\boldsymbol{x}}}}_i'{{{\boldsymbol{\beta}}}}+ {{\epsilon}}_i, \quad i=1,\cdots,n.
\]</span></p>
<p>where <span class="math inline">\({{\epsilon}}_i, i=1,\cdots,n\)</span> are iid with mean 0 and variance 1.</p>
<ol start="3" style="list-style-type: decimal">
<li>Location-Scale Mean and Quantile Regression Model</li>
</ol>
<p><span class="math display">\[
  y_i = {{{\boldsymbol{x}}}}_i'{{{\boldsymbol{\beta}}}}+ \sigma\cdot\exp({{{\boldsymbol{z}}}}_i'{{{\boldsymbol{\gamma}}}})\cdot{{\epsilon}}_i, \quad i=1,\cdots,n.
\]</span></p>
<p>where <span class="math inline">\({{\epsilon}}_i, i=1,\cdots,n\)</span> are iid with mean 0 and variance 1.</p>
</div>
<div id="future-works" class="section level2">
<h2>Future Works</h2>
<ol style="list-style-type: decimal">
<li>The gradient approach has not been integrated in the C++ code</li>
<li>Confidence intervals evaluation has not been included in the package</li>
</ol>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-chen-et-al2008">
<p>Chen, Jiahua, Asokan Mulayath Variyath, and Bovas Abraham. 2008. “Adjusted Empirical Likelihood and Its Properties.” <em>Journal of Computational and Graphical Statistics</em> 17 (2). Taylor &amp; Francis: 426–43.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
